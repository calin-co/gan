{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s17/s1737865/miniconda3/envs/mlp/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "z_dim = 10\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(input):\n",
    "    '''\n",
    "    input = [28*28, batch_size] array\n",
    "    return the prob of being real \n",
    "    '''\n",
    "    h0 = tf.layers.dense(input, 28*28, activation = tf.nn.relu, name='d0')\n",
    "    h1 = tf.layers.dense(h0, 1,  name='d1')\n",
    "    #prob = tf.sigmoid(h1, 'd2')\n",
    "    \n",
    "    return h1\n",
    "\n",
    "def generator(inputs):\n",
    "    '''\n",
    "    receives random noise and tries to reproduce mnist image\n",
    "    '''\n",
    "    h0 = tf.layers.dense(inputs, 100, activation=tf.nn.relu, name='g0')\n",
    "    h1 = tf.layers.dense(h0, 28*28, name='g1')\n",
    "    h2 = tf.sigmoid(h1, name='g2')\n",
    "    return h2\n",
    "\n",
    "\n",
    "with tf.variable_scope('G'):\n",
    "    z = tf.placeholder(tf.float32, shape=[None, 100], name='z')\n",
    "    fake_samples = generator(z)\n",
    "   \n",
    "    \n",
    "with tf.variable_scope('D') as scope:\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='inputs')\n",
    "    D_real = discriminator(x)\n",
    "    scope.reuse_variables()\n",
    "    D_fake = discriminator(fake_samples)\n",
    "    \n",
    "\n",
    "vars = tf.trainable_variables()\n",
    "d_params = [v for v in vars if v.name.startswith('D/')]\n",
    "g_params = [v for v in vars if v.name.startswith('G/')]\n",
    "\n",
    "loss_d =  tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)\n",
    "loss_g = - tf.reduce_mean(D_fake)\n",
    "\n",
    "    \n",
    "d_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)\n",
    "            .minimize(-loss_d, var_list=d_params))\n",
    "g_solver = (tf.train.RMSPropOptimizer(learning_rate=1e-4)\n",
    "            .minimize(loss_g, var_list=g_params))\n",
    "    \n",
    "\n",
    "clip_d = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in d_params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0235181 0.0324269\n",
      "11.7966 9.07108\n",
      "10.9656 8.18624\n",
      "9.90709 6.75073\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9e30fca64604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             loss_disc, _, _ = sess.run([loss_d, d_solver, clip_d], {\n\u001b[1;32m     24\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             })\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 100000\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            save_path = saver.save(sess, \"../tmp/model.ckpt\")\n",
    "\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            fake_data = sess.run(fake_samples, feed_dict={z: sample_Z(16, 100)})\n",
    "            fig = plot(fake_data)\n",
    "            plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "\n",
    "        for n_critic in range(5):\n",
    "            train_data, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            #update discriminator\n",
    "            loss_disc, _, _ = sess.run([loss_d, d_solver, clip_d], {\n",
    "                x: train_data,\n",
    "                z: sample_Z(batch_size, 100)\n",
    "            })\n",
    "\n",
    "        #update generator\n",
    "        loss_gen, _ = sess.run([loss_g, g_solver], {\n",
    "            z: sample_Z(batch_size, 100)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(loss_disc, loss_gen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vanilla gan\n",
    "\"\"\"\n",
    "def discriminator(input):\n",
    "    '''\n",
    "    input = [28*28, batch_size] array\n",
    "    return the prob of being real \n",
    "    '''\n",
    "    h0 = tf.layers.dense(input, 28*28, activation = tf.nn.relu, name='d0')\n",
    "    h1 = tf.layers.dense(h0, 1,  name='d1')\n",
    "    prob = tf.sigmoid(h1, 'd2')\n",
    "    \n",
    "    return prob\n",
    "\n",
    "def generator(inputs):\n",
    "    '''\n",
    "    receives random noise and tries to reproduce mnist image\n",
    "    '''\n",
    "    h0 = tf.layers.dense(inputs, 100, activation=tf.nn.relu, name='g0')\n",
    "    h1 = tf.layers.dense(h0, 28*28, name='g1')\n",
    "    h2 = tf.sigmoid(h1, name='g2')\n",
    "    return h2\n",
    "\n",
    "\n",
    "with tf.variable_scope('G'):\n",
    "    z = tf.placeholder(tf.float32, shape=[None, 100], name='z')\n",
    "    fake_samples = generator(z)\n",
    "   \n",
    "    \n",
    "with tf.variable_scope('D') as scope:\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='inputs')\n",
    "    D1 = discriminator(x)\n",
    "    scope.reuse_variables()\n",
    "    D2 = discriminator(fake_samples)\n",
    "    \n",
    "\n",
    "vars = tf.trainable_variables()\n",
    "d_params = [v for v in vars if v.name.startswith('D/')]\n",
    "g_params = [v for v in vars if v.name.startswith('G/')]\n",
    "\n",
    "loss_d = - tf.reduce_mean(tf.log(D1) + tf.log(1.0 - D2))\n",
    "loss_g = - tf.reduce_mean(tf.log(D2))\n",
    "    \n",
    "d_optimizer = tf.train.AdamOptimizer().minimize(loss_d, var_list=d_params)\n",
    "g_optimizer = tf.train.AdamOptimizer().minimize(loss_g, var_list=g_params)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 59,  62,  63, ..., 123,  92,  72], dtype=uint8), array([125, 125, 116, ..., 144, 116,  86], dtype=uint8), array([ 62,  64,  44, ..., 169, 156, 160], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from os import listdir\n",
    "import sys\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "import numpy\n",
    "\n",
    "arr = []\n",
    "counter  = 0\n",
    "in_path = \"train/\"\n",
    "out_path = \"./\"\n",
    "\n",
    "#num_files = len(listdir(in_path))\n",
    "#print(\"Total number of files: %s\" % num_files)\n",
    "\n",
    "for f in listdir(in_path):\n",
    "\n",
    "    counter += 1\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"%s out of %s files done\" % (counter, num_files))\n",
    "\n",
    "    im_path = join(in_path, f)\n",
    "    if not isfile(im_path): continue\n",
    "\n",
    "    try:\n",
    "\n",
    "        im = Image.open(im_path)\n",
    "        pix = numpy.array(im)\n",
    "        pix = np.reshape(pix, (32*32*3))\n",
    "        arr.append(pix)\n",
    "        if counter == 3:\n",
    "            break\n",
    "        #im_out_path = join(out_path, f)\n",
    "        #im_out.save(im_out_path, format='JPEG')\n",
    "    except:\n",
    "        print(\"%s couldn't be resized\" % im_path)\n",
    "        \n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.vstack(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3072)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.savez(\"cifar10\", arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
